Retrospective
=====================

Overestimating the number of features we could create before Iteration 2 was due was one of the biggest problems we ran into while working on our project. This resulted in lower quality code (bugs and code smells) and a hurried development approach, which eventually increased the amount of work we must do in iteration 3. For iteration 3, we must concentrate on establishing attainable goals that we can finish within the allotted time frame in order to avoid this issue.

One action we can take to improve our strategy is to divide the project into smaller, easier-to-manage activities and prioritize them according to their significance and complexity. This would allow us to set realistic deadlines and targets for each work and move forward steadily towards them. In order to raise the standard of our code and lower the amount of bugs, we may also set aside enough time for code review and refactoring.

By counting the number of features finished within the time Iteration 2 was due and comparing it to our initial estimation, we can assess the effectiveness of this strategy. The quantity of problems reported in the software after each iteration, as well as code smells, can be used to evaluate the overall quality of the code. These will let us evaluate the success of our strategy.

Prioritizing testing during each iteration is another option to improve our strategy. Regular testing will help us find and fix errors early on, minimizing the amount of catch-up work needed in following iterations. 

By counting the number of software issues that are reported after each iteration and comparing the results with previous iterations, we can assess the effectiveness of this strategy. This will enable us to evaluate the success of our strategy.

Finally, we can evaluate our strategy by periodically assessing our user stories as we work on new features. By doing this, we can make sure that the features we are creating are beneficial to and pertinent to our target audience. This will enable us to avoid wasting time on features that won't benefit our users.

By measuring how closely the features that have been deployed adhere to the project's vision, we may determine whether this strategy has been successful. This will enable us to evaluate the success of our strategy.

In conclusion, we may make consistent progress towards our objectives and deadlines while retaining the quality of our code and software if we acknowledge the difficulties we ran into during our previous iteration and take practical and realistic actions to enhance our approach. We may continuously enhance and direct upcoming versions of the project by evaluating the performance of our efforts against specific, quantifiable goals. We can make sure that we are creating features that are valuable and relevant to our target audience by giving testing and attainable goals first priority.
